{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch is a popular deep learning framework and it's easy to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the mnist data, preprocess them and encapsulate them into dataloader form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "normalize = transforms.Normalize(mean=[.5], std=[.5])\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "# download and load the data\n",
    "train_dataset = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./mnist/', train=False, transform=transform, download=False)\n",
    "\n",
    "# encapsulate them into dataloader form\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the model, object function and optimizer that we use to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "# TODO:define model\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(1,10,5) # 10, 24x24\n",
    "        self.conv2=nn.Conv2d(10,20,3) # 128, 10x10\n",
    "        self.fc1 = nn.Linear(20*10*10,500)\n",
    "        self.fc2 = nn.Linear(500,10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        out = self.conv1(x) #24\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2)  #12\n",
    "        out = self.conv2(out) #10\n",
    "        out = F.relu(out)\n",
    "        out = out.view(in_size,-1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = F.log_softmax(out,dim=1)\n",
    "        return out\n",
    "\n",
    "# TODO:define loss function and optimiter\n",
    "model = SimpleNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can start to train and evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:26<00:00, 17.93it/s]\n",
      "100%|██████████| 78/78 [00:03<00:00, 21.65it/s]\n",
      "  0%|          | 2/468 [00:00<00:28, 16.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] Train Loss: 0.19863 Train Accuracy: 0.93863\n",
      "[Epoch: 1] Test Loss: 0.06097 Test Accuracy: 0.97930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:25<00:00, 18.01it/s]\n",
      "100%|██████████| 78/78 [00:03<00:00, 20.98it/s]\n",
      "  0%|          | 2/468 [00:00<00:27, 16.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 2] Train Loss: 0.05335 Train Accuracy: 0.98223\n",
      "[Epoch: 2] Test Loss: 0.03972 Test Accuracy: 0.98520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:27<00:00, 17.11it/s]\n",
      "100%|██████████| 78/78 [00:03<00:00, 21.80it/s]\n",
      "  0%|          | 2/468 [00:00<00:29, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 3] Train Loss: 0.03663 Train Accuracy: 0.98708\n",
      "[Epoch: 3] Test Loss: 0.03352 Test Accuracy: 0.98760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:25<00:00, 18.30it/s]\n",
      "100%|██████████| 78/78 [00:03<00:00, 19.55it/s]\n",
      "  0%|          | 2/468 [00:00<00:30, 15.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 4] Train Loss: 0.02614 Train Accuracy: 0.99020\n",
      "[Epoch: 4] Test Loss: 0.04088 Test Accuracy: 0.98500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:29<00:00, 15.65it/s]\n",
      "100%|██████████| 78/78 [00:05<00:00, 14.89it/s]\n",
      "  0%|          | 2/468 [00:00<00:29, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 5] Train Loss: 0.02037 Train Accuracy: 0.99192\n",
      "[Epoch: 5] Test Loss: 0.03477 Test Accuracy: 0.98710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [01:12<00:00,  6.47it/s]\n",
      "100%|██████████| 78/78 [00:11<00:00,  6.77it/s]\n",
      "  0%|          | 1/468 [00:00<01:09,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 6] Train Loss: 0.01467 Train Accuracy: 0.99372\n",
      "[Epoch: 6] Test Loss: 0.03700 Test Accuracy: 0.98720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [01:02<00:00,  7.46it/s]\n",
      "100%|██████████| 78/78 [00:08<00:00,  8.79it/s]\n",
      "  0%|          | 1/468 [00:00<01:10,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 7] Train Loss: 0.01205 Train Accuracy: 0.99447\n",
      "[Epoch: 7] Test Loss: 0.03768 Test Accuracy: 0.98720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:58<00:00,  7.93it/s]\n",
      "100%|██████████| 78/78 [00:09<00:00,  8.24it/s]\n",
      "  0%|          | 1/468 [00:00<01:23,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 8] Train Loss: 0.00951 Train Accuracy: 0.99530\n",
      "[Epoch: 8] Test Loss: 0.04532 Test Accuracy: 0.98660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:59<00:00,  7.82it/s]\n",
      "100%|██████████| 78/78 [00:08<00:00,  8.86it/s]\n",
      "  0%|          | 1/468 [00:00<00:59,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 9] Train Loss: 0.01142 Train Accuracy: 0.99468\n",
      "[Epoch: 9] Test Loss: 0.04133 Test Accuracy: 0.98740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [01:00<00:00,  7.80it/s]\n",
      "100%|██████████| 78/78 [00:08<00:00,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 10] Train Loss: 0.00744 Train Accuracy: 0.99592\n",
      "[Epoch: 10] Test Loss: 0.04957 Test Accuracy: 0.98430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        # TODO:forward + backward + optimize\n",
    "        # Init\n",
    "        optimizer.zero_grad()\n",
    "        # Predict\n",
    "        y_train_pred = model(images) \n",
    "        # Calculate loss\n",
    "        loss = nn.functional.cross_entropy(y_train_pred, labels)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss\n",
    "        train_correct += (torch.max(y_train_pred, 1)[1].view(labels.size()).data == labels.data).sum()\n",
    "    for images0, labels0 in tqdm(test_loader): \n",
    "        y_pred = model(images0) \n",
    "        # Calculate loss\n",
    "        loss0 = nn.functional.cross_entropy(y_pred, labels0)\n",
    "        # Backpropagation\n",
    "        loss0.backward()\n",
    "        \n",
    "        test_loss += loss0\n",
    "        test_correct += (torch.max(y_pred, 1)[1].view(labels0.size()).data == labels0.data).sum()\n",
    "        \n",
    "    # evaluate\n",
    "    # TODO:calculate the accuracy using traning and testing dataset\n",
    "    train_loss = train_loss.item() / len(train_loader)\n",
    "    train_accuracy = train_correct.item() / len(train_loader.dataset)\n",
    "    test_loss = test_loss.item() / len(test_loader)\n",
    "    test_accuracy = test_correct.item() / len(test_loader.dataset)\n",
    "    print(\"[Epoch: %d] Train Loss: %5.5f Train Accuracy: %5.5f\" % (epoch+1, train_loss, train_accuracy))\n",
    "    print(\"[Epoch: %d] Test Loss: %5.5f Test Accuracy: %5.5f\" % (epoch+1, test_loss, test_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5:\n",
    "Please print the training and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.59%\n",
      "Testing accuracy: 98.43%\n"
     ]
    }
   ],
   "source": [
    "print('Training accuracy: %0.2f%%' % (train_accuracy*100))\n",
    "print('Testing accuracy: %0.2f%%' % (test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
